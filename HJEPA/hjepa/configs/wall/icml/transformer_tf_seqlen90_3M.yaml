base_lr: 0.0003255
data:
  dataset_type: DatasetType.Wall
  min_max_normalize_state: true
  normalize: true
  offline_wall_config:
    batch_size: 64
    device: cuda
    img_size: 65
    lazy_load: false
    n_steps: 16
    offline_data_path: /scratch/us441/datasets/wall/wall-visual-config_rand_expert_40-v0.npz
    train: true
    use_offline: true
  wall_config:
    action_angle_noise: 0.2
    action_bias_only: false
    action_lower_bd: 0.2
    action_noise: 1
    action_param_xy: true
    action_step_mean: 1.0
    action_step_std: 0.4
    action_upper_bd: 1.8
    batch_size: 64
    border_wall_loc: 5
    cross_wall_rate: 0.08
    device: cuda
    door_padding: 10
    door_space: 4
    dot_std: 1.3
    exclude_door_train: ''
    exclude_wall_train: ''
    expert_cross_wall_rate: 0
    fix_door_location: 10
    fix_wall: true
    fix_wall_batch_k: null
    fix_wall_location: 32
    img_size: 65
    max_step: 1
    n_steps: 16
    n_steps_reduce_factor: 1
    num_train_layouts: -1
    only_door_val: ''
    only_wall_val: ''
    repeat_actions: 1
    size: 20000
    train: true
    val_size: 10000
    wall_padding: 20
    wall_width: 3
env_name: wall
epochs: 2
eval_at_beginning: false
eval_cfg:
  env_name: wall
  log_heatmap: false
  probing:
    epochs: 20
    epochs_enc: 30
    full_finetune: false
    l1_depth: 16
    locations:
      arch: '512'
    lr: 0.0002
    probe_encoder: true
    probe_mpc: false
    probe_targets: locations
    probe_wall: true
    sample_timesteps: 30
    schedule: Constant
    visualize_probing: true
  wall_planning:
    easy:
      max_plan_length: 96
      n_envs: 100
      n_steps: 50
      override_config: true
    level1:
      loss_coeff_first: 0.1
      loss_coeff_last: 1
      max_plan_length: 96
      max_step: 2.45
      min_step: 0
      mppi:
        lambda_: 0.005
        noise_sigma: 12
        num_samples: 2000
        z_reg_coeff: 0
      planner_type: PlannerType.MPPI
      repr_target: true
      sum_all_diffs: false
    levels: medium
    medium:
      max_plan_length: 96
      n_envs: 100
      n_steps: 200
      override_config: true
    n_envs: 100
    n_envs_batch_size: 20
    n_steps: 200
    seed: 42
eval_during_training: false
eval_mpcs: 20
eval_only: false
hjepa:
  disable_l2: true
  freeze_l1: false
  l1_n_steps: 16
  level1:
    action_dim: 2
    backbone:
      arch: impala
      backbone_final_fc: false
      backbone_mlp: null
      backbone_norm: group_norm
      backbone_pool: dim_reduce
      backbone_subclass: i
      backbone_width_factor: 2
      channels: 2
      final_ln: true
      input_dim: null
    momentum: 0
    predictor:
      dropout: 0.15206
      predictor_arch: transformer
      predictor_ln: true
      tie_backbone_ln: true
      transformer_activation: relu
      transformer_dim_feedforward: 1024
      transformer_max_seq_len: 64
      transformer_nhead: 2
      transformer_num_layers: 1
      transformer_teacher_forcing_ratio: 0.47439862456484627
      use_checkpointing: true
      use_teacher_forcing: true
      z_dim: 0
      z_min_std: 0.1
  step_skip: 4
  train_l1: true
load_checkpoint_path: null
load_l1_only: false
n_steps: 16
objectives_l1:
  idm:
    action_dim: 2
    arch: '512'
    arch_subclass: a
    coeff: 1.5634671752069598
    use_pred: false
  objectives:
  - VICReg
  vicreg:
    adjust_cov: true
    cov_chunk_size: null
    cov_coeff: 2.8852
    cov_coeff_t: 0.0
    cov_per_feature: false
    projector: id
    random_projector: false
    sim_coeff: 6.3093
    sim_coeff_t: 1.5213
    std_coeff: 30.541
    std_coeff_t: 0.10722
    std_margin: 1.0
    std_margin_t: 1.0
optimizer_type: Adam
output_dir: trial_1
output_root: checkpoint
quick_debug: false
run_name: transformer_tf_seqlen90_3M
run_project: HJEPA-wall
seed: 101
val_n_steps: 16
wandb: true